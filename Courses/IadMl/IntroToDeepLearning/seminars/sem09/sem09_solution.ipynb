{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d340bf",
   "metadata": {
    "id": "06d340bf"
   },
   "source": [
    "# Классификация последовательностей (текстов) -- good practices\n",
    "\n",
    "На прошлом семинаре мы рассмотрели пример генерации текстов. Однако мы не обсудили весь огромный функционал, который предоставляет пайторч для работы с текстами. В частности работали мы с посимвольной генерацией, а не пословной/потокенной. Исправляемся!\n",
    "\n",
    "Сегодня речь зайдёт о задаче классификации текстовых последовательностей. Для этого будем пользоваться датасетом IMDB и библиотекой `torchtext`. В торчтексте реализовано огромное число методов для обработки текстов, ими мы и воспользуемся.\n",
    "\n",
    "__АХТУНГ__. Торчтекст не рекомендуется использовать для обучения на больших данных (от миллиона примеров и больше) из-за маленькой скорости работы. В таких случаях рекомендуется имплементировать свои датасеты. В наших примерах таких объёмов данных не будет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5cd1db",
   "metadata": {
    "id": "ac5cd1db"
   },
   "source": [
    "## Начнём с модели.\n",
    "\n",
    "Да, не самая привыичная последовательность действий, но давайте сначала сделаем кое-что, с чем мы уже знакомы -- имплементируем модель.\n",
    "\n",
    "На вход она будет принимать батч последовательностей токенов, разумеется разной длины в разных батчах, а на выходе выдавать батч вероятностей классов, прямо как в классификации картинок.\n",
    "\n",
    "Каждый токен пройдёт вначале через эмбеддинг, а затем последовательность эмбеддингов пройдёт через LSTM. Самое последнее скрытое состояние будем считать векторным представлением для последовательности, поверх неё мы навесим линейный слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a7a3b1",
   "metadata": {
    "id": "88a7a3b1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings=25002, embedding_size=300, hidden_size=200, num_classes=2, num_layers=1):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (last_hidden, last_c) = self.lstm(embedded)\n",
    "        return self.linear(last_hidden[0]).squeeze()\n",
    "\n",
    "model = TextClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2c5c61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff2c5c61",
    "outputId": "16cc9774-eb02-4bbe-ca05-4bbae0b33ad7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2758, 0.2758], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[1,2,3,4], [1,2,3,4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73797236",
   "metadata": {
    "id": "73797236"
   },
   "source": [
    "## Скачаем и проинициализируем датасет\n",
    "\n",
    "Дальше перейдём к торчтексту. Он почти как знакомый нам `torchvision` имеет внутри себя коллекцию датасетов для разных задач NLP в том числе и отзывы на IMDB. Инициализация датасета порой занимает время, не следует волноваться и судорожно перезапускать ядро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddfb36e",
   "metadata": {
    "id": "4ddfb36e"
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.datasets import IMDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444cf930",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "444cf930",
    "outputId": "2a9c748b-e3d5-4758-c0cf-aee6cf546fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\n",
      "     |████████████████████████████████| 6.1 MB 1.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: jinja2 in /home/seara/.local/lib/python3.9/site-packages (from spacy) (3.0.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Downloading pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "     |████████████████████████████████| 11.3 MB 10.0 MB/s            \n",
      "\u001b[?25hCollecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 11.5 MB/s            \n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "     |████████████████████████████████| 128 kB 10.6 MB/s            \n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Downloading srsly-2.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
      "     |████████████████████████████████| 452 kB 11.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy) (1.21.2)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from spacy) (57.4.0)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "     |████████████████████████████████| 9.9 MB 7.8 MB/s            \n",
      "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from spacy) (20.9)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Downloading thinc-8.0.13-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (635 kB)\n",
      "     |████████████████████████████████| 635 kB 11.5 MB/s            \n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 1.1 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.9/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 9.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/seara/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seara/.local/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seara/.local/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.5 catalogue-2.0.6 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.6 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0 wasabi-0.9.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "     |████████████████████████████████| 13.9 MB 11.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/seara/.local/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/seara/.local/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/seara/.local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/seara/.local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: idna>=2.5 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/seara/.local/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/seara/.local/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# spacy -- вспомогательная библоитека для токенизации текста, скачаем токенайзер для английского языка\n",
    "! pip install spacy\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73f01f",
   "metadata": {
    "id": "2f73f01f"
   },
   "source": [
    "В `torchtext` существует такая сущность, как `Field`. Это просто класс, в котором содержится описание колонок нашего датасета. В нашем случае всё довольно просто. Есть две колонки --- это текст и оценка, назовём их `text_field` и `label_field` соответственно. Токенизовать будем при помощи установленной только что библиотеки `spacy`, лейблы приведём к типу `float`. Разумеется, как и на прошлом семинаре ставим batch_first=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ace08bb",
   "metadata": {
    "id": "7ace08bb"
   },
   "outputs": [],
   "source": [
    "\n",
    "text_field = data.Field(tokenize='spacy',\n",
    "                        batch_first=True,\n",
    "                        include_lengths=False,\n",
    "                        tokenizer_language='en_core_web_sm')\n",
    "\n",
    "label_field = data.LabelField(dtype=torch.float32, batch_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ea62e",
   "metadata": {
    "id": "ee4ea62e"
   },
   "source": [
    "Создадим два сплита нашего датасета. Они задаются при помощи метода splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27834eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c27834eb",
    "outputId": "b9db8caf-de79-4f55-ee01-ae86c8fd1e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84.1M/84.1M [00:06<00:00, 13.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = IMDB.splits(text_field, label_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2120f86",
   "metadata": {
    "id": "c2120f86"
   },
   "source": [
    "Создадим также словари, соответствующие нашему тексту. Выкинем все слова (токены), которые встречаются редко. Оставим только 25 тысяч самых частых слов.\n",
    "\n",
    "Также согласуем номера токенов в словаре с эмбеддингами glove. При желании можно согласовать и с word2vec'ом, но имейте ввиду, что glove это их аналог. Об инициализации эмбеддингов мы обязательно поговорим чуть позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d142a6af",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d142a6af",
    "outputId": "0214340d-ebcb-4202-ed05-ed14e53fb507"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:47, 5.14MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:22<00:00, 18096.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cheech', '&', 'Chong', \"'s\", 'Next', 'Movie', '(', '1980', ')', 'was', 'the', 'second', 'film', 'to', 'star', 'to', 'pot', 'loving', 'duo', 'of', 'Cheech', 'Marin', 'and', 'Tommy', 'Chong', '.', 'The', 'lovable', 'burn', 'out', 'smokers', 'are', 'now', 'roommates', '.', 'They', 'live', 'in', 'a', 'condemned', 'building', 'looking', 'for', 'ways', 'to', 'score', 'more', 'smoke', 'and', 'just', 'lay', 'about', 'all', 'day', '.', 'But', 'Cheech', 'is', 'the', '\"', 'responsible', '\"', 'one', '.', 'He', 'has', 'a', 'job', 'and', 'a', 'steady', 'girlfriend', '.', 'One', 'day', ',', 'Cheech', 'wants', 'to', 'get', 'his', 'freak', 'on', 'so', 'he', 'tries', 'to', 'get', 'Chong', 'out', 'of', 'the', 'house', '.', 'Another', 'problem', 'arises', 'as', 'well', ',', 'Cheech', \"'s\", 'brother', '\"', 'Red', '\"', '(', 'Cheech', 'is', 'another', 'role', ')', 'is', 'in', 'town', 'and', 'wants', 'to', 'hang', 'with', 'him', '.', 'Firguring', 'that', 'he', 'could', 'kill', 'two', 'birds', 'with', 'one', 'stone', ',', 'Cheech', 'pawns', 'Chong', 'off', 'and', 'Red', '.', 'What', 'kind', 'of', 'adventures', 'will', 'Chong', 'and', 'Red', 'get', 'into', '?', 'Will', 'Cheech', 'get', 'his', 'freak', 'on', '?', 'How', 'long', 'will', 'Chong', 'go', 'without', 'some', 'smoke', '?', 'Just', 'watch', 'CHEECH', '&', 'CHONG', \"'S\", 'NEXT', 'MOVIE', 'to', 'find', 'out!!<br', '/><br', '/>Tommy', 'Chong', 'takes', 'over', 'the', 'directorial', 'reigns', 'for', 'the', 'sequel', '.', 'He', 'received', 'some', 'experience', 'when', 'he', 'did', 'some', 'uncredited', 'work', 'on', 'UP', 'IN', 'SMOKE', '.', 'Funny', 'but', 'not', 'as', 'good', 'as', 'the', 'first', 'film', '.', 'But', 'Cheech', 'and', 'Chong', 'fans', 'will', 'enjoy', 'it', '.', 'Followed', 'by', 'NICE', 'DREAMS.<br', '/><br', '/>Recommended', '.']\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 25000\n",
    "\n",
    "# build_vocab -- создать словарь по данному полю в датасете\n",
    "text_field.build_vocab(data_train,\n",
    "                       max_size=vocab_size,\n",
    "                       vectors=\"glove.6B.100d\",\n",
    "                      )\n",
    "\n",
    "label_field.build_vocab(data_train)\n",
    "\n",
    "\n",
    "for item in data_train:\n",
    "    print(item.text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022be96a",
   "metadata": {
    "id": "022be96a"
   },
   "source": [
    "Давайте посмотрим на самые частые токены в словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2932700",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2932700",
    "outputId": "17e58650-ca7f-49d1-a8de-42c0d4967bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 289838),\n",
       " (',', 275296),\n",
       " ('.', 236843),\n",
       " ('and', 156483),\n",
       " ('a', 156282),\n",
       " ('of', 144055),\n",
       " ('to', 133886),\n",
       " ('is', 109095),\n",
       " ('in', 87676),\n",
       " ('I', 77546)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6c62077",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6c62077",
    "outputId": "8d889870-8227-4d84-e190-f16026f20904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itos -- index to string\n",
    "text_field.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "l42uaghGd3gl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l42uaghGd3gl",
    "outputId": "b850d7ea-13e0-4e5b-e120-4ead9568be25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a5c4e29",
   "metadata": {
    "id": "5a5c4e29"
   },
   "source": [
    "Как мы видим, в поле текста у нас стоят токены, на которые поделил spacy поделил текст! Осталось только воспользоваться построенным словарём и сделать аналог даталоадера по данным!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c2e38b7",
   "metadata": {
    "id": "5c2e38b7"
   },
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = data.BucketIterator.splits((data_train, data_test), batch_size=32, device=\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d042926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d042926",
    "outputId": "7783ad29-2796-4e50-deba-0112bd262d9f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1263]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataloader:\n",
    "    print(item.text.shape, item.label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379f8d4",
   "metadata": {
    "id": "5379f8d4"
   },
   "source": [
    "1077 это очень много для нашей маленькой модельки. Будем обрезать их на 256 токенах в нашем трейн лупе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c2675",
   "metadata": {
    "id": "366c2675"
   },
   "source": [
    "## Train loop\n",
    "\n",
    "Перейдём к самому интересному (нет) и построим трейн луп к нашей модели. Но скажем сразу, он мало чем будет отличаться от классификации картинок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "566445fc",
   "metadata": {
    "id": "566445fc"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    return_losses=False,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model = model.to(device).train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_losses = []\n",
    "    total_predictions = np.array([])#.reshape((0, ))\n",
    "    total_labels = np.array([])#.reshape((0, ))\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for item in data_loader:\n",
    "            images = item.text\n",
    "            labels = item.label\n",
    "\n",
    "            # Move Batch to GPU\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            # Update weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Update descirption for tqdm\n",
    "            accuracy = ((predicted > 0.5).int() == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions,(predicted > 0.5).int().cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "            all_losses.append(loss.detach().item())\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    if return_losses:\n",
    "        return metrics, all_losses\n",
    "    else:\n",
    "        return metrics\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device=\"cuda:0\"):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    total_predictions = np.array([])\n",
    "    total_labels = np.array([])\n",
    "    with tqdm(total=len(data_loader), file=sys.stdout) as prbar:\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            predicted = model(images)\n",
    "            loss = criterion(predicted, labels)\n",
    "            accuracy = (predicted.argmax(1) == labels).float().mean()\n",
    "            prbar.set_description(\n",
    "                f\"Loss: {round(loss.item(), 4)} \"\n",
    "                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n",
    "            )\n",
    "            prbar.update(1)\n",
    "            total_loss += loss.item()\n",
    "            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n",
    "            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n",
    "            num_batches += 1\n",
    "    metrics = {\"loss\": total_loss / num_batches}\n",
    "    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a9825e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413,
     "referenced_widgets": [
      "fe79da413ee74722adbfa9accd88d04c",
      "684eac4d36b444238fe2be0d86dc77dd",
      "215832372b924a8ca8e0f84d282eaa39",
      "a78e50ea6b4946e99a624a877014f974",
      "c6f3e12422a94a5b9e1d3baa139bb7cc",
      "033b2ced711d425490fde6f8bea834f8",
      "dc2e957748ec41a6b7f715ce4294e368",
      "78c98b6dd3994c58b3aacc775d48113c",
      "371b720785c04c138a10cf7d05707d40",
      "1c62971a214143dab87d48b8eff9f960",
      "00d4052aaeec4f43889ec9f60dd0df62"
     ]
    },
    "id": "6a9825e1",
    "outputId": "0a89b936-641d-43cc-a7a8-dadc1a05b9bb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe79da413ee74722adbfa9accd88d04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-25fe81c2cd14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-040ab5920a0c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, return_losses, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "device=\"cuda:0\"\n",
    "model = TextClassifier()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for i in range(10):\n",
    "    train_epoch(model, train_dataloader, criterion=criterion, optimizer=optimizer, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EttH3QDVcVnE",
   "metadata": {
    "id": "EttH3QDVcVnE"
   },
   "source": [
    "Кажется, обучается так себе. Давайте это исправлять! Попробуем сделать модель двунаправленной, а также увеличим число слоёв. Должно быть существенно лучше!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "Dvua6cZRcU2h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "a39ab87f7d164a489f7e525334e13072",
      "7a30cbc0d2e44e0dbc6c68611b261812",
      "710e277a8fe0435e9955625492a3b038",
      "6162ad50a2c24666a0d1721b8f31bec2",
      "3b3db9889ec54e6f9488b71c7f966805",
      "2b242fd0d2054b95adced0b41d0f1c05",
      "1e9826762091465f916e4a87788f45b2",
      "356bf6cb62df46b2a0476c98c0ccfdfd",
      "2426eea53d944048a91ed1b20d3f8846",
      "6eb512c778914e7ab30c7577ed9694b3",
      "b2de4192ce1c4caabf29de96d0a02b25"
     ]
    },
    "id": "Dvua6cZRcU2h",
    "outputId": "ee97bef4-61a8-4bef-d729-55e24a0ad559"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39ab87f7d164a489f7e525334e13072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-733432c9c072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-040ab5920a0c>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, return_losses, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-733432c9c072>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, num_embeddings=25002, embedding_size=300, hidden_size=200, num_classes=2, num_layers=1, pad_token=1):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, padding_idx=pad_token)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True, num_layers=num_layers, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_size * num_layers, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        _, (last_hidden, last_c) = self.lstm(embedded)\n",
    "        hidden = torch.cat([last_hidden[-2], last_hidden[-1]], dim=1)\n",
    "        return self.linear(hidden).squeeze()\n",
    "\n",
    "device=\"cuda:0\"\n",
    "pad_token = text_field.vocab.stoi['<pad>']\n",
    "model = TextClassifier(hidden_size=512, embedding_size=100, num_layers=2, pad_token=pad_token)\n",
    "model.embedding.weight.data = text_field.vocab.vectors\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for i in range(10):\n",
    "    train_epoch(model, train_dataloader, criterion=criterion, optimizer=optimizer, device=device)\n",
    "\n",
    "model(torch.tensor([[1,2,3,4], [1,2,3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336be296",
   "metadata": {
    "id": "336be296"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sem_n1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00d4052aaeec4f43889ec9f60dd0df62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "033b2ced711d425490fde6f8bea834f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c62971a214143dab87d48b8eff9f960": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e9826762091465f916e4a87788f45b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "215832372b924a8ca8e0f84d282eaa39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc2e957748ec41a6b7f715ce4294e368",
      "placeholder": "​",
      "style": "IPY_MODEL_033b2ced711d425490fde6f8bea834f8",
      "value": "Loss: 0.6916 Accuracy: 53.125:   1%"
     }
    },
    "2426eea53d944048a91ed1b20d3f8846": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b242fd0d2054b95adced0b41d0f1c05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "356bf6cb62df46b2a0476c98c0ccfdfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "371b720785c04c138a10cf7d05707d40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b3db9889ec54e6f9488b71c7f966805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2de4192ce1c4caabf29de96d0a02b25",
      "placeholder": "​",
      "style": "IPY_MODEL_6eb512c778914e7ab30c7577ed9694b3",
      "value": " 3/782 [00:03&lt;14:28,  1.11s/it]"
     }
    },
    "6162ad50a2c24666a0d1721b8f31bec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2426eea53d944048a91ed1b20d3f8846",
      "max": 782,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_356bf6cb62df46b2a0476c98c0ccfdfd",
      "value": 3
     }
    },
    "684eac4d36b444238fe2be0d86dc77dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6eb512c778914e7ab30c7577ed9694b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "710e277a8fe0435e9955625492a3b038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e9826762091465f916e4a87788f45b2",
      "placeholder": "​",
      "style": "IPY_MODEL_2b242fd0d2054b95adced0b41d0f1c05",
      "value": "Loss: 0.6876 Accuracy: 43.75:   0%"
     }
    },
    "78c98b6dd3994c58b3aacc775d48113c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a30cbc0d2e44e0dbc6c68611b261812": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a39ab87f7d164a489f7e525334e13072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_710e277a8fe0435e9955625492a3b038",
       "IPY_MODEL_6162ad50a2c24666a0d1721b8f31bec2",
       "IPY_MODEL_3b3db9889ec54e6f9488b71c7f966805"
      ],
      "layout": "IPY_MODEL_7a30cbc0d2e44e0dbc6c68611b261812"
     }
    },
    "a78e50ea6b4946e99a624a877014f974": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_371b720785c04c138a10cf7d05707d40",
      "max": 782,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78c98b6dd3994c58b3aacc775d48113c",
      "value": 9
     }
    },
    "b2de4192ce1c4caabf29de96d0a02b25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6f3e12422a94a5b9e1d3baa139bb7cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00d4052aaeec4f43889ec9f60dd0df62",
      "placeholder": "​",
      "style": "IPY_MODEL_1c62971a214143dab87d48b8eff9f960",
      "value": " 9/782 [00:03&lt;03:49,  3.37it/s]"
     }
    },
    "dc2e957748ec41a6b7f715ce4294e368": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe79da413ee74722adbfa9accd88d04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_215832372b924a8ca8e0f84d282eaa39",
       "IPY_MODEL_a78e50ea6b4946e99a624a877014f974",
       "IPY_MODEL_c6f3e12422a94a5b9e1d3baa139bb7cc"
      ],
      "layout": "IPY_MODEL_684eac4d36b444238fe2be0d86dc77dd"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
